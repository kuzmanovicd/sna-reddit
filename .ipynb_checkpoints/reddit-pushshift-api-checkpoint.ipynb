{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json, time, datetime, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from requests_futures.sessions import FuturesSession\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "ROOT_PATH = 'data/'\n",
    "DATA_PATH = '-'.join(str(x) for x in [(now.year), now.month, now.day])\n",
    "\n",
    "def print_time(msg, unix):\n",
    "    print(msg, time.ctime(int(unix)))\n",
    "    \n",
    "def get_readable_time(unix):\n",
    "    return [time.ctime(int(u)) for u in unix]\n",
    "\n",
    "def print_progress(iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, errors = 0, fill = '+'):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s - errors: %s' % (prefix, bar, percent, suffix, errors), end = '\\r')\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total - 1: \n",
    "        print()\n",
    "        \n",
    "def retrieve_data(url):\n",
    "    r = requests.get(url)    \n",
    "    if(r.status_code >= 400):\n",
    "        print('Sleeping for one minute...')\n",
    "        time.sleep(60)\n",
    "        return retrieve_data(url)\n",
    "    else:\n",
    "        return r\n",
    "\n",
    "def query_data(url, *args, **kwargs):\n",
    "    payload = {}\n",
    "    if kwargs is not None:\n",
    "        for key, value in kwargs.items():\n",
    "            payload[key] = value\n",
    "    print(payload)\n",
    "    \n",
    "    new_url = url\n",
    "    if args is not None:\n",
    "        for value in args:\n",
    "            new_url = new_url + value + '/'\n",
    "    print(new_url)\n",
    "    r = requests.get(url, params=payload)    \n",
    "    if(400 <= r.status_code < 500):\n",
    "        print(r.status_code, ' Trying again')\n",
    "        time.sleep(1)\n",
    "        return query_data(url, *args, **kwargs)\n",
    "    elif r.status_code >= 500:\n",
    "        print('Server error:', r.status_code, r.content)\n",
    "        print(r.request.body, r.request.headers)\n",
    "        return None\n",
    "    else:\n",
    "        return r.json()\n",
    "\n",
    "def query_data_future(session, url, *args, **kwargs):\n",
    "    payload = {}\n",
    "    if kwargs is not None:\n",
    "        for key, value in kwargs.items():\n",
    "            payload[key] = value\n",
    "    #print(payload)\n",
    "    new_url = url\n",
    "    if args is not None:\n",
    "        for value in args:\n",
    "            new_url = new_url + value + '/'\n",
    "    #print(new_url)\n",
    "    r = session.get(url, params=payload)    \n",
    "    return r\n",
    "\n",
    "def save_data(df, name):\n",
    "    if os.path.isdir(ROOT_PATH + DATA_PATH) == False:\n",
    "        os.mkdir(ROOT_PATH + DATA_PATH)\n",
    "        print('Creating', DATA_PATH, 'directory...')\n",
    "    df.to_pickle(ROOT_PATH + DATA_PATH + '/' + name)\n",
    "    \n",
    "\n",
    "URL_COM = 'https://api.pushshift.io/reddit/search/comment/'\n",
    "URL_SUB = 'https://api.pushshift.io/reddit/search/submission/'\n",
    "\n",
    "QUERIES = ['bitcoin', 'ethereum', 'crypto', 'ripple', 'litecoin', 'btc']\n",
    "DROP_SUBREDDITS = ['AskReddit', 'news', 'Sexsells']\n",
    "TOP_SUBREDDITS_TO_QUERY = 20\n",
    "DOWNLOAD_NEW_DATA = False\n",
    "LOAD_DATA_PATH = '2018-2-5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q': 'bitcoin', 'size': 0, 'aggs': 'subreddit', 'after': '30d'}\n",
      "https://api.pushshift.io/reddit/search/comment/\n",
      "{'q': 'ethereum', 'size': 0, 'aggs': 'subreddit', 'after': '30d'}\n",
      "https://api.pushshift.io/reddit/search/comment/\n",
      "{'q': 'crypto', 'size': 0, 'aggs': 'subreddit', 'after': '30d'}\n",
      "https://api.pushshift.io/reddit/search/comment/\n",
      "{'q': 'ripple', 'size': 0, 'aggs': 'subreddit', 'after': '30d'}\n",
      "https://api.pushshift.io/reddit/search/comment/\n",
      "{'q': 'litecoin', 'size': 0, 'aggs': 'subreddit', 'after': '30d'}\n",
      "https://api.pushshift.io/reddit/search/comment/\n",
      "{'q': 'btc', 'size': 0, 'aggs': 'subreddit', 'after': '30d'}\n",
      "https://api.pushshift.io/reddit/search/comment/\n",
      "    bg_count  doc_count                  key     score\n",
      "0    1521817      40812              Bitcoin   2.68179\n",
      "1     676344      27633                  btc   4.08564\n",
      "2    1559250      22551       CryptoCurrency   1.44627\n",
      "3     153798       9978           BitcoinAll   6.48773\n",
      "4      45201       6630  noncensored_bitcoin  14.66782\n",
      "5     285720       6140       BitcoinMarkets   2.14896\n",
      "6     740446       5661            ethtrader   0.76454\n",
      "7      62712       3596             Buttcoin   5.73415\n",
      "8     290118       2595               Ripple   0.89446\n",
      "9    1350445       1835         pcmasterrace   0.13588\n",
      "10    180451       1797            RaiBlocks   0.99584\n",
      "11     26680       1619             xyMarket   6.06822\n",
      "12    179150       1560            investing   0.87078\n",
      "13     52570       1440     BitcoinBeginners   2.73920\n",
      "14    236659       1408             litecoin   0.59495\n",
      "15    623007       1376           technology   0.22086\n",
      "16   3211589       1342            worldnews   0.04179\n",
      "17    109448       2767             ethereum   2.52814\n",
      "18     83739        492          EtherMining   0.58754\n",
      "19    121796        477                  NEO   0.39164\n",
      "20    127896        466               Tronix   0.36436\n",
      "21     72056        434              Vechain   0.60231\n",
      "22     30856        405                  eos   1.31255\n",
      "23     53744        403             omise_go   0.74985\n",
      "24     83405        400        CryptoMarkets   0.47959\n",
      "25    107010        379              Stellar   0.35417\n",
      "26     17812        936                  XRP   5.25488\n",
      "27      4784        155              gatehub   3.23997\n",
      "28     36444        130         ledgerwallet   0.35671\n",
      "29    109137       1035      LitecoinMarkets   0.94835\n",
      "30     98251        297             dogecoin   0.30229\n",
      "31    180942        186            garlicoin   0.10280\n",
      "32     91713        153             vertcoin   0.16682\n",
      "33     81269        106             CoinBase   0.13043\n",
      "34    103419       2347             NiceHash   2.26941\n",
      "35     32497       1197             RaiTrade   3.68342\n",
      "36     58541        904          Bitcoincash   1.54422\n",
      "37      9976        891     BitGrailExchange   8.93144\n"
     ]
    }
   ],
   "source": [
    "# Retrieve top 10 subreddits for each query\n",
    "popular_subreddits = []\n",
    "popular_subreddits_df = pd.DataFrame()\n",
    "if DOWNLOAD_NEW_DATA:    \n",
    "    for query in QUERIES:\n",
    "        tmp_data = query_data(URL_COM, q=query, size=0, aggs='subreddit', after='30d')['aggs']['subreddit'][0:TOP_SUBREDDITS_TO_QUERY]\n",
    "        popular_subreddits.extend(tmp_data)\n",
    "\n",
    "    popular_subreddits_df = pd.DataFrame(popular_subreddits)\n",
    "    popular_subreddits_df = popular_subreddits_df.drop_duplicates('key').reset_index(drop=True)\n",
    "    popular_subreddits_df = popular_subreddits_df[~popular_subreddits_df['key'].isin(DROP_SUBREDDITS)].reset_index(drop=True)\n",
    "    save_data(popular_subreddits_df, 'popular_subreddits.pkl')\n",
    "else:\n",
    "    popular_subreddits_df = pd.read_pickle(ROOT_PATH + LOAD_DATA_PATH + '/' + 'popular_subreddits.pkl')\n",
    "    popular_subreddits = popular_subreddits_df.to_dict()\n",
    "    \n",
    "#TEMP - DELETE\n",
    "print(popular_subreddits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...+++++++++++++++++++++++++++++++++++++++++++++++++-| 100.0% 4559/4560 - errs: 0\n"
     ]
    }
   ],
   "source": [
    "TIME_STEP = 6\n",
    "START_AFTER = 24\n",
    "DAYS = 30\n",
    "\n",
    "sub_fields = ['author', 'subreddit', 'score', 'num_comments']\n",
    "sub_fields_save = ['author', 'subreddit_id', 'subreddit', 'score', 'num_comments', 'id', 'created_utc', 'retrieved_on', 'num_crossposts', 'title', 'url', 'stickied', 'pinned', 'gilded', ]\n",
    "\n",
    "submissions = []\n",
    "submissions_df = pd.DataFrame()\n",
    "fut = []\n",
    "errors = []\n",
    "with FuturesSession(max_workers=10) as session:\n",
    "    for i, sub in popular_subreddits_df.iterrows(): \n",
    "        for idx in range(int(24/TIME_STEP * DAYS)):\n",
    "            _before = str(TIME_STEP*idx + START_AFTER) + 'h'\n",
    "            _after = str(TIME_STEP*(idx+1) + START_AFTER) + 'h'\n",
    "            fut.append(query_data_future(session, URL_SUB, subreddit=sub['key'], size=500, before=_before, after=_after))\n",
    "        if i > 1:\n",
    "            pass\n",
    "            #break\n",
    "            \n",
    "    for idx in range(len(fut)):\n",
    "        print_progress(idx, len(fut), prefix = 'Start', suffix = str(idx) + '/' + str(len(fut)), length=50, errors=len(errors))\n",
    "        tmp = {}\n",
    "        try:\n",
    "            tmp = fut[idx].result().json()['data']\n",
    "            submissions.append(pd.DataFrame(tmp))\n",
    "            if idx and idx % 30 == 0:\n",
    "                submissions_df = pd.concat(submissions)[sub_fields_save].query('num_comments>1').reset_index(drop=True)\n",
    "                save_data(submissions_df, 'submissions_df.pkl')\n",
    "        except:\n",
    "            errors.append(fut[idx]) \n",
    "    \n",
    "    submissions_df = pd.concat(submissions)[sub_fields_save].query('num_comments>1').reset_index(drop=True)\n",
    "    save_data(submissions_df, 'submissions_df.pkl')\n",
    "    print('Done...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      author       subreddit  score  num_comments\n",
      "0       SuperficialPickle444       garlicoin  52479         49636\n",
      "1                     Amidza      technology  70405          6870\n",
      "2                 skyler4722       garlicoin  64137          6544\n",
      "3        Religion__of__Peace       garlicoin   2433          5099\n",
      "4           acacia-club-road      technology  34667          4838\n",
      "5                       mvea      technology  92622          4489\n",
      "6                    Z_staff    pcmasterrace    613          4443\n",
      "7              Gabriel-Lewis  CryptoCurrency  18038          4231\n",
      "8                       mvea      technology  57675          3767\n",
      "9                       mvea      technology  26800          3674\n",
      "10       A_Internet_Stranger  CryptoCurrency  35935          3396\n",
      "11                      mvea      technology  34105          3362\n",
      "12                    speckz      technology  47406          3358\n",
      "13            MichaelRahmani      technology  18870          3304\n",
      "14                 jake15151  CryptoCurrency  51752          3142\n",
      "15                    speckz      technology  40395          2969\n",
      "16                sumphatguy    pcmasterrace  18420          2862\n",
      "17                 BluntLord         Bitcoin  10400          2708\n",
      "18                    Amidza      technology  15933          2695\n",
      "19               rBitcoinMod         Bitcoin    106          2652\n",
      "20                      mvea      technology  52237          2614\n",
      "21         DigitalizedOrange       garlicoin   1889          2518\n",
      "22               remi9martin       garlicoin   4783          2446\n",
      "23                   Evan532      technology  21395          2404\n",
      "24                ttminh1997    pcmasterrace  23795          2339\n",
      "25               rBitcoinMod         Bitcoin     95          2290\n",
      "26               lawmaster99         Bitcoin  13406          2285\n",
      "27         DigitalizedOrange       garlicoin   3490          2282\n",
      "28                AdamCannon      technology  73651          2132\n",
      "29           Pirate_Redbeard    pcmasterrace  25398          2045\n",
      "...                      ...             ...    ...           ...\n",
      "104097            CreaDorMan    pcmasterrace      1             2\n",
      "104098        sevenoverthree    pcmasterrace      1             2\n",
      "104099               malitos    pcmasterrace      2             2\n",
      "104100           ChrisWalley    pcmasterrace      0             2\n",
      "104101             tjaustin2    pcmasterrace      1             2\n",
      "104102             Bossgdt09    pcmasterrace      2             2\n",
      "104103          GingaMonstar    pcmasterrace      1             2\n",
      "104104         CPRyouserious    pcmasterrace      0             2\n",
      "104105         cryptoflasher         Stellar      2             2\n",
      "104106             grifdaddy    pcmasterrace      1             2\n",
      "104107            Synthisis_    pcmasterrace      0             2\n",
      "104108        Baron_Von_Sexy    pcmasterrace      0             2\n",
      "104109          pleasedoELI5         Stellar      2             2\n",
      "104110          EtenalLimitz    pcmasterrace      1             2\n",
      "104111          GingaMonstar    pcmasterrace      1             2\n",
      "104112              Barkalow    pcmasterrace      1             2\n",
      "104113           jmoncaleano         Stellar     16             2\n",
      "104114                  JKO_    pcmasterrace      0             2\n",
      "104115         FourteenCoast    pcmasterrace      1             2\n",
      "104116        1papafucktard1    pcmasterrace      0             2\n",
      "104117              Plexicle    pcmasterrace      1             2\n",
      "104118             ___Galaxy    pcmasterrace      0             2\n",
      "104119          Youthinasia-    pcmasterrace      1             2\n",
      "104120       cryptocodewatch         Stellar     20             2\n",
      "104121        TWTHEREDDRAGON         Stellar      5             2\n",
      "104122       Cookiemonster52    pcmasterrace      2             2\n",
      "104123         _Jay_Garrick_    pcmasterrace      2             2\n",
      "104124              Gek_Lhar    pcmasterrace      0             2\n",
      "104125        shitcoinballer         Stellar      1             2\n",
      "104126             Btc91help  BitcoinMarkets      0             2\n",
      "\n",
      "[104127 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "submissions_df = (submissions_df\n",
    "      .sort_values(by=['num_comments'], ascending=False)\n",
    "      .query('subreddit!=\"worldnews\"&author!=\"AutoModerator\"&author!=\"[deleted]\"')\n",
    "      .reset_index(drop=True))\n",
    "print(submissions_df[sub_fields])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fut: 0\n",
      "fut: 1\n",
      "fut: 2\n",
      "fut: 3\n",
      "fut: 4\n",
      "fut: 5\n",
      "fut: 6\n",
      "fut: 7\n",
      "fut: 8\n",
      "fut: 9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "9355\n"
     ]
    }
   ],
   "source": [
    "#get comment ids for every submission obtained above\n",
    "#concurrent calls\n",
    "fut = []\n",
    "comment_ids = []\n",
    "num_calls = 10\n",
    "with FuturesSession(max_workers=50) as session:\n",
    "    for i, sub in bitcoin_submissions.iterrows():\n",
    "        fut.append(session.get('https://api.pushshift.io/reddit/submission/comment_ids/' + sub.loc['id']))\n",
    "        print('fut:', i)\n",
    "        if i >= num_calls - 1:\n",
    "            pass\n",
    "            break\n",
    "        \n",
    "    for i in range(len(fut)):\n",
    "        print(i)\n",
    "        tmp = fut[i].result()\n",
    "        tmp = tmp.json()['data']\n",
    "        comment_ids.extend(tmp)\n",
    "\n",
    "print(len(comment_ids))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtkd1na\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "9354\n"
     ]
    }
   ],
   "source": [
    "#get data for every comment\n",
    "#print(comment_ids[-1])\n",
    "\n",
    "print(','.join(comment_ids[0:1]))\n",
    "#r = query_data(URL_COM, ids=','.join(comment_ids[0:2]))\n",
    "\n",
    "NUM_CONCAT = 500\n",
    "fut = []\n",
    "comment_data = []\n",
    "with FuturesSession(max_workers=5) as session:\n",
    "    _done = 0\n",
    "    idx = 0\n",
    "    while _done != -1:\n",
    "        print('working')\n",
    "        _end = _done + NUM_CONCAT\n",
    "        if _end >= len(comment_ids) + 1:\n",
    "            _end = -1\n",
    "        fut.append(session.get('https://api.pushshift.io/reddit/search/comment/?ids=' + ','.join(comment_ids[_done:_end])))\n",
    "        _done = _end\n",
    "    \n",
    "    for i in range(len(fut)):\n",
    "        print(i)\n",
    "        tmp = fut[i].result()\n",
    "        tmp = tmp.json()['data']\n",
    "        comment_data.extend(tmp)\n",
    "        \n",
    "    #print(r)\n",
    "print(len(comment_data))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type prefixes\n",
    "t1_\tComment\n",
    "t2_\tAccount\n",
    "t3_\tLink\n",
    "t4_\tMessage\n",
    "t5_\tSubreddit\n",
    "t6_\tAward"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "author_1 -> comment(score, ups) -> author_2\n",
    "\n",
    "simplified\n",
    "\n",
    "author_1 -> comment_on_sub -> author_2\n",
    "author_1 -> reply_on_comment -> author_2\n",
    "\n",
    "author_1 -> submission -> subreddit\n",
    "author_1 -> comment_on_sub -> subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'approved_at_utc': None, 'author': 'Asdn1220', 'author_flair_background_color': '', 'author_flair_css_class': None, 'author_flair_richtext': [], 'author_flair_text': None, 'author_flair_text_color': 'dark', 'author_flair_type': 'text', 'banned_at_utc': None, 'body': 'I am panicking', 'can_mod_post': False, 'collapsed': False, 'collapsed_reason': None, 'created_utc': 1517479281, 'distinguished': None, 'edited': False, 'id': 'dtkd1na', 'is_submitter': False, 'link_id': 't3_7uhqjf', 'mod_note': None, 'mod_reason_by': None, 'mod_reason_title': None, 'parent_id': 't3_7uhqjf', 'permalink': '/r/Bitcoin/comments/7uhqjf/daily_discussion_february_01_2018/dtkd1na/', 'retrieved_on': 1517479283, 'rte_mode': 'markdown', 'score': 1, 'stickied': False, 'subreddit': 'Bitcoin', 'subreddit_id': 't5_2s3qj'}\n"
     ]
    }
   ],
   "source": [
    "comments_df = pd.DataFrame(comment_data)\n",
    "print(comment_data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
