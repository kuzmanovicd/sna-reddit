{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json, time, datetime, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from requests_futures.sessions import FuturesSession\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "ROOT_PATH = 'data/'\n",
    "DATA_PATH = '-'.join(str(x) for x in [(now.year), now.month, now.day])\n",
    "\n",
    "def print_time(msg, unix):\n",
    "    print(msg, time.ctime(int(unix)))\n",
    "    \n",
    "def get_readable_time(unix):\n",
    "    return [time.ctime(int(u)) for u in unix]\n",
    "\n",
    "def print_progress(iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, errors = 0, fill = '+'):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s - errors: %s' % (prefix, bar, percent, suffix, errors), end = '\\r')\n",
    "    # Print New Line on Complete\n",
    "    if iteration == (total - 2): \n",
    "        print()\n",
    "        \n",
    "def retrieve_data(url):\n",
    "    r = requests.get(url)    \n",
    "    if(r.status_code >= 400):\n",
    "        print('Sleeping for one minute...')\n",
    "        time.sleep(60)\n",
    "        return retrieve_data(url)\n",
    "    else:\n",
    "        return r\n",
    "\n",
    "def query_data(url, *args, **kwargs):\n",
    "    payload = {}\n",
    "    if kwargs is not None:\n",
    "        for key, value in kwargs.items():\n",
    "            payload[key] = value\n",
    "    print(payload)\n",
    "    \n",
    "    new_url = url\n",
    "    if args is not None:\n",
    "        for value in args:\n",
    "            new_url = new_url + value + '/'\n",
    "    print(new_url)\n",
    "    r = requests.get(url, params=payload)    \n",
    "    if(400 <= r.status_code < 500):\n",
    "        print(r.status_code, ' Trying again')\n",
    "        time.sleep(1)\n",
    "        return query_data(url, *args, **kwargs)\n",
    "    elif r.status_code >= 500:\n",
    "        print('Server error:', r.status_code, r.content)\n",
    "        print(r.request.body, r.request.headers)\n",
    "        return None\n",
    "    else:\n",
    "        return r.json()\n",
    "\n",
    "def query_data_future(session, url, *args, **kwargs):\n",
    "    payload = {}\n",
    "    if kwargs is not None:\n",
    "        for key, value in kwargs.items():\n",
    "            payload[key] = value\n",
    "    #print(payload)\n",
    "    new_url = url\n",
    "    if args is not None:\n",
    "        for value in args:\n",
    "            new_url = new_url + value + '/'\n",
    "    #print(new_url)\n",
    "    r = session.get(url, params=payload)    \n",
    "    return r\n",
    "\n",
    "def save_data(df, name):\n",
    "    if os.path.isdir(ROOT_PATH + DATA_PATH) == False:\n",
    "        os.mkdir(ROOT_PATH + DATA_PATH)\n",
    "        print('Creating', DATA_PATH, 'directory...')\n",
    "    df.to_pickle(ROOT_PATH + DATA_PATH + '/' + name)\n",
    "    \n",
    "\n",
    "URL_COM = 'https://api.pushshift.io/reddit/search/comment/'\n",
    "URL_SUB = 'https://api.pushshift.io/reddit/search/submission/'\n",
    "\n",
    "QUERIES = ['bitcoin', 'ethereum', 'crypto', 'ripple', 'litecoin', 'btc']\n",
    "DROP_SUBREDDITS = ['AskReddit', 'news', 'Sexsells']\n",
    "TOP_SUBREDDITS_TO_QUERY = 20\n",
    "DOWNLOAD_NEW_DATA = False\n",
    "LOAD_DATA_PATH = '2018-2-5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top 10 subreddits for each query\n",
    "popular_subreddits = []\n",
    "popular_subreddits_df = pd.DataFrame()\n",
    "if DOWNLOAD_NEW_DATA:    \n",
    "    for query in QUERIES:\n",
    "        tmp_data = query_data(URL_COM, q=query, size=0, aggs='subreddit', after='30d')['aggs']['subreddit'][0:TOP_SUBREDDITS_TO_QUERY]\n",
    "        popular_subreddits.extend(tmp_data)\n",
    "\n",
    "    popular_subreddits_df = pd.DataFrame(popular_subreddits)\n",
    "    popular_subreddits_df = popular_subreddits_df.drop_duplicates('key').reset_index(drop=True)\n",
    "    popular_subreddits_df = popular_subreddits_df[~popular_subreddits_df['key'].isin(DROP_SUBREDDITS)].reset_index(drop=True)\n",
    "    save_data(popular_subreddits_df, 'popular_subreddits.pkl')\n",
    "else:\n",
    "    popular_subreddits_df = pd.read_pickle(ROOT_PATH + LOAD_DATA_PATH + '/' + 'popular_subreddits.pkl')\n",
    "    popular_subreddits = popular_subreddits_df.to_dict()\n",
    "    \n",
    "#TEMP - DELETE\n",
    "#print(popular_subreddits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissions successfully loaded\n"
     ]
    }
   ],
   "source": [
    "TIME_STEP = 6\n",
    "START_AFTER = 24\n",
    "DAYS = 30\n",
    "\n",
    "sub_fields = ['id', 'author', 'subreddit', 'score', 'num_comments']\n",
    "sub_fields_save = ['author', 'subreddit_id', 'subreddit', 'score', 'num_comments', 'id', 'created_utc', 'retrieved_on', 'num_crossposts', 'title', 'url', 'stickied', 'pinned', 'gilded', ]\n",
    "\n",
    "submissions = []\n",
    "submissions_df = pd.DataFrame()\n",
    "fut = []\n",
    "errors = []\n",
    "if DOWNLOAD_NEW_DATA:\n",
    "    with FuturesSession(max_workers=10) as session:\n",
    "        for i, sub in popular_subreddits_df.iterrows(): \n",
    "            for idx in range(int(24/TIME_STEP * DAYS)):\n",
    "                _before = str(TIME_STEP*idx + START_AFTER) + 'h'\n",
    "                _after = str(TIME_STEP*(idx+1) + START_AFTER) + 'h'\n",
    "                fut.append(query_data_future(session, URL_SUB, subreddit=sub['key'], size=500, before=_before, after=_after))\n",
    "            if i > 1:\n",
    "                pass\n",
    "                #break\n",
    "\n",
    "        for idx in range(len(fut)):\n",
    "            print_progress(idx, len(fut), prefix = 'Start', suffix = str(idx) + '/' + str(len(fut)), length=50, errors=len(errors))\n",
    "            tmp = {}\n",
    "            try:\n",
    "                tmp = fut[idx].result().json()['data']\n",
    "                submissions.append(pd.DataFrame(tmp))\n",
    "                if idx and idx % 30 == 0:\n",
    "                    submissions_df = pd.concat(submissions)[sub_fields_save].query('num_comments>1').reset_index(drop=True)\n",
    "                    save_data(submissions_df, 'submissions.pkl')\n",
    "            except:\n",
    "                errors.append(fut[idx]) \n",
    "\n",
    "        submissions_df = pd.concat(submissions)[sub_fields_save].query('num_comments>1').reset_index(drop=True)\n",
    "        save_data(submissions_df, 'submissions.pkl')\n",
    "        print('Downloading submissions done...')\n",
    "else:\n",
    "    submissions_df = pd.read_pickle(ROOT_PATH + LOAD_DATA_PATH + '/' + 'submissions.pkl')\n",
    "    print('Submissions successfully loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                author subreddit  score  num_comments\n",
      "0     7qvjuv             BluntLord   Bitcoin  10400          2708\n",
      "1     7r0001           rBitcoinMod   Bitcoin    106          2652\n",
      "2     7qrbuz           rBitcoinMod   Bitcoin     95          2290\n",
      "3     7or2i6           lawmaster99   Bitcoin  13406          2285\n",
      "4     7uhqjf           rBitcoinMod   Bitcoin     84          1798\n",
      "5     7uqa54          xcryptogurux   Bitcoin   3476          1751\n",
      "6     7qr4ym             trance929   Bitcoin  27264          1617\n",
      "7     7s5yjd                 B3nGG   Bitcoin   4060          1607\n",
      "8     7trstp             lriccardo   Bitcoin  10657          1604\n",
      "9     7uqbwv           rBitcoinMod   Bitcoin     69          1591\n",
      "10    7u9zbd             Xtreme110   Bitcoin  26661          1224\n",
      "11    7rfwec           suasponte26   Bitcoin   7091          1156\n",
      "12    7qypup             sunilross   Bitcoin   2161          1112\n",
      "13    7v5ydz           rBitcoinMod   Bitcoin     52          1034\n",
      "14    7sx64q        pc_to_mac_user   Bitcoin  10199           973\n",
      "15    7u00iy           rBitcoinMod   Bitcoin     53           902\n",
      "16    7olruz           buttockpain   Bitcoin  40005           877\n",
      "17    7u2zpe             sdfk3294m   Bitcoin    686           822\n",
      "18    7tl7gi  entrepreneurharshita   Bitcoin   3714           818\n",
      "19    7pemxx           rBitcoinMod   Bitcoin     48           809\n",
      "20    7uhyy5             David3692   Bitcoin   5760           801\n",
      "21    7v438b          Tricky_Troll   Bitcoin  45770           795\n",
      "22    7r1b92    IDidReadTheSideBar   Bitcoin    677           783\n",
      "23    7u4tnh                 codna   Bitcoin   3175           781\n",
      "24    7tcmi4           lonely_guy0   Bitcoin   7297           757\n",
      "25    7owib7          Nedtherlandz   Bitcoin   6655           751\n",
      "26    7sln7i           UnocoinTeam   Bitcoin   4511           704\n",
      "27    7pe3rx               Svensis   Bitcoin    486           701\n",
      "28    7rb03f             Kill3rism   Bitcoin   1936           699\n",
      "29    7pn3ts           rBitcoinMod   Bitcoin     78           668\n",
      "...      ...                   ...       ...    ...           ...\n",
      "1444  7s5ic2           DeadlyViper   Bitcoin      4            26\n",
      "1445  7r8o6f           crystalannr   Bitcoin      1            26\n",
      "1446  7omy4v               jmineer   Bitcoin      0            26\n",
      "1447  7thxo5                 ssesq   Bitcoin     26            26\n",
      "1448  7q9kaf           moneymayhem   Bitcoin     17            26\n",
      "1449  7t99wi           BakersDozen   Bitcoin     28            26\n",
      "1450  7qjm5z         weedogcodeine   Bitcoin      0            26\n",
      "1451  7ttwbu                pdipps   Bitcoin     35            26\n",
      "1452  7tr6rm                pwinne   Bitcoin      0            26\n",
      "1453  7tujue          manzholmgren   Bitcoin      3            26\n",
      "1454  7r84xg        bhishmapitamah   Bitcoin      0            26\n",
      "1455  7rne6s              movimike   Bitcoin      2            26\n",
      "1456  7os0uz             Bjartleif   Bitcoin     76            26\n",
      "1457  7rjtcg        insatiableevil   Bitcoin      3            26\n",
      "1458  7psn1a            Rufio-1408   Bitcoin      0            26\n",
      "1459  7om6if         ImJustACowLol   Bitcoin     62            26\n",
      "1460  7ov8lc   10XUnicornNinjaGuru   Bitcoin     17            26\n",
      "1461  7ons8w               Castrox   Bitcoin     91            26\n",
      "1462  7sg605         wheresbitcoin   Bitcoin      3            26\n",
      "1463  7sl393               BUnit17   Bitcoin      0            26\n",
      "1464  7pt5vy          MikhailG5000   Bitcoin     21            26\n",
      "1465  7pbccj         wisestaccount   Bitcoin     31            26\n",
      "1466  7sl255       BurntAccountant   Bitcoin      4            26\n",
      "1467  7pi147              yonderoy   Bitcoin      1            26\n",
      "1468  7rjain        tharussianphil   Bitcoin      7            26\n",
      "1469  7sghqd             chefticus   Bitcoin     43            26\n",
      "1470  7pfhf5      EasyTechPrincess   Bitcoin      0            26\n",
      "1471  7pkhrt              wallyjo3   Bitcoin      1            26\n",
      "1472  7pfdgk               13_777k   Bitcoin      0            26\n",
      "1473  7sjftf           karamelitar   Bitcoin    757            26\n",
      "\n",
      "[1474 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "submissions_df = submissions_df.sort_values(by=['num_comments'], ascending=False).query('subreddit!=\"worldnews\"&author!=\"AutoModerator\"&author!=\"[deleted]\"').reset_index(drop=True)\n",
    "submissions_df = submissions_df.query('subreddit==\"Bitcoin\"&num_comments>25').reset_index(drop=True)\n",
    "print(submissions_df[sub_fields])\n",
    "#print(submissions_df[submissions_df['author'].str.contains('Bot')][sub_fields])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Start |+++++++++++++++++++++++++++++++++++++++++++++++++-| 99.9% 1472/1474 - errors: 0\n",
      "180561|+++++++++++++++++++++++++++++++++++++++++++++++++-| 99.9% 1473/1474 - errors: 0\n"
     ]
    }
   ],
   "source": [
    "#get comment ids for every submission obtained above\n",
    "#concurrent calls\n",
    "fut = []\n",
    "comment_ids = []\n",
    "comment_ids_df = pd.DataFrame()\n",
    "errors = []\n",
    "IDS_DOWNLOAD = False\n",
    "if IDS_DOWNLOAD:\n",
    "    with FuturesSession(max_workers=10) as session:\n",
    "        print('Starting...')\n",
    "        for i, sub in submissions_df.iterrows():\n",
    "            fut.append(session.get('https://api.pushshift.io/reddit/submission/comment_ids/' + sub.loc['id']))\n",
    "\n",
    "        for i in range(len(fut)):\n",
    "            print_progress(i, len(fut), prefix = 'Start', suffix = str(i) + '/' + str(len(fut)), length=50, errors=len(errors))\n",
    "            try:\n",
    "                tmp = fut[i].result()\n",
    "                tmp = tmp.json()['data']\n",
    "                comment_ids.extend(tmp)\n",
    "            except:\n",
    "                print(fut[i].result().status_code)\n",
    "                errors.append(fut[i])\n",
    "                \n",
    "        comment_ids_df = pd.DataFrame({\n",
    "            'id': comment_ids\n",
    "        })\n",
    "        save_data(comment_ids_df, 'comment_ids.pkl')\n",
    "else:\n",
    "    comment_ids_df = pd.read_pickle(ROOT_PATH + LOAD_DATA_PATH + '/' + 'comment_ids.pkl')\n",
    "    print('Comment ids successfully loaded...')\n",
    "    \n",
    "print(len(comment_ids))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1474 entries, 0 to 1473\n",
      "Data columns (total 14 columns):\n",
      "author            1474 non-null object\n",
      "subreddit_id      1474 non-null object\n",
      "subreddit         1474 non-null object\n",
      "score             1474 non-null int64\n",
      "num_comments      1474 non-null int64\n",
      "id                1474 non-null object\n",
      "created_utc       1474 non-null int64\n",
      "retrieved_on      1474 non-null int64\n",
      "num_crossposts    1474 non-null int64\n",
      "title             1474 non-null object\n",
      "url               1474 non-null object\n",
      "stickied          1474 non-null bool\n",
      "pinned            1474 non-null bool\n",
      "gilded            29 non-null float64\n",
      "dtypes: bool(2), float64(1), int64(5), object(6)\n",
      "memory usage: 141.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(submissions_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtkd1na\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "9354\n"
     ]
    }
   ],
   "source": [
    "#get data for every comment\n",
    "NUM_CONCAT = 500\n",
    "fut = []\n",
    "comments = []\n",
    "if True:\n",
    "    with FuturesSession(max_workers=5) as session:\n",
    "        _done = 0\n",
    "        idx = 0\n",
    "        while _done != -1:\n",
    "            _end = _done + NUM_CONCAT\n",
    "            if _end >= len(comment_ids) + 1:\n",
    "                _end = -1\n",
    "            fut.append(session.get('https://api.pushshift.io/reddit/search/comment/?ids=' + ','.join(comment_ids[_done:_end])))\n",
    "            _done = _end\n",
    "\n",
    "        for i in range(len(fut)):\n",
    "            print_progress(i, len(fut), prefix = 'Start', suffix = str(i) + '/' + str(len(fut)), length=50, errors=len(errors))\n",
    "            try:\n",
    "            tmp = fut[i].result()\n",
    "            tmp = tmp.json()['data']\n",
    "            comments.extend(tmp)\n",
    "else:\n",
    "    pass\n",
    "    #print(r)\n",
    "print(len(comments))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type prefixes\n",
    "t1_\tComment\n",
    "t2_\tAccount\n",
    "t3_\tLink\n",
    "t4_\tMessage\n",
    "t5_\tSubreddit\n",
    "t6_\tAward"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "author_1 -> comment(score, ups) -> author_2\n",
    "\n",
    "simplified\n",
    "\n",
    "author_1 -> comment_on_sub -> author_2\n",
    "author_1 -> reply_on_comment -> author_2\n",
    "\n",
    "author_1 -> submission -> subreddit\n",
    "author_1 -> comment_on_sub -> subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'approved_at_utc': None, 'author': 'Asdn1220', 'author_flair_background_color': '', 'author_flair_css_class': None, 'author_flair_richtext': [], 'author_flair_text': None, 'author_flair_text_color': 'dark', 'author_flair_type': 'text', 'banned_at_utc': None, 'body': 'I am panicking', 'can_mod_post': False, 'collapsed': False, 'collapsed_reason': None, 'created_utc': 1517479281, 'distinguished': None, 'edited': False, 'id': 'dtkd1na', 'is_submitter': False, 'link_id': 't3_7uhqjf', 'mod_note': None, 'mod_reason_by': None, 'mod_reason_title': None, 'parent_id': 't3_7uhqjf', 'permalink': '/r/Bitcoin/comments/7uhqjf/daily_discussion_february_01_2018/dtkd1na/', 'retrieved_on': 1517479283, 'rte_mode': 'markdown', 'score': 1, 'stickied': False, 'subreddit': 'Bitcoin', 'subreddit_id': 't5_2s3qj'}\n"
     ]
    }
   ],
   "source": [
    "comments_df = pd.DataFrame(comment_data)\n",
    "print(comment_data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
