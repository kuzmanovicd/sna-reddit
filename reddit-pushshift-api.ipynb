{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json, time, datetime, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from requests_futures.sessions import FuturesSession\n",
    "\n",
    "def print_time(msg, unix):\n",
    "    print(msg, time.ctime(int(unix)))\n",
    "    \n",
    "def get_readable_time(unix):\n",
    "    return [time.ctime(int(u)) for u in unix]\n",
    "\n",
    "def print_progress(iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '+'):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    ETA = (total - iteration) * 60/REQUESTS_PER_MIN\n",
    "    estimated = datetime.datetime.now() + datetime.timedelta(seconds=ETA)\n",
    "    ETA = estimated - datetime.datetime.now()\n",
    "    print('\\r%s |%s| %s%% %s - ETA: %s - %s' % (prefix, bar, percent, suffix, ETA, estimated), end = '\\r')\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()\n",
    "        \n",
    "def retrieve_data(url):\n",
    "    r = requests.get(url)    \n",
    "    if(r.status_code >= 400):\n",
    "        print('Sleeping for one minute...')\n",
    "        time.sleep(60)\n",
    "        return retrieve_data(url)\n",
    "    else:\n",
    "        return r\n",
    "\n",
    "def query_data(url, *args, **kwargs):\n",
    "    payload = {}\n",
    "    if kwargs is not None:\n",
    "        for key, value in kwargs.items():\n",
    "            payload[key] = value\n",
    "    print(payload)\n",
    "    \n",
    "    new_url = url\n",
    "    if args is not None:\n",
    "        for value in args:\n",
    "            new_url = new_url + value + '/'\n",
    "    \n",
    "    print(new_url)\n",
    "    \n",
    "    r = requests.get(url, params=payload)    \n",
    "    if(400 <= r.status_code < 500):\n",
    "        print(r.status_code, ' Trying again')\n",
    "        time.sleep(1)\n",
    "        return query_data(url, *args, **kwargs)\n",
    "    elif r.status_code >= 500:\n",
    "        print('Server error:', r.status_code, r.content)\n",
    "        print(r.request.body, r.request.headers)\n",
    "        return None\n",
    "    else:\n",
    "        return r.json()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q': 'bitcoin', 'size': 10, 'after': '1d', 'subreddit': 'bitcoin'}\n",
      "https://api.pushshift.io/reddit/search/comment/\n",
      "{'q': 'bitcoin', 'size': 0, 'aggs': 'subreddit', 'after': '30d'}\n",
      "https://api.pushshift.io/reddit/search/comment/\n"
     ]
    }
   ],
   "source": [
    "URL_COM = 'https://api.pushshift.io/reddit/search/comment/'\n",
    "URL_SUB = 'https://api.pushshift.io/reddit/search/submission/'\n",
    "\n",
    "response = query_data(URL_COM, q='bitcoin', size=10, after='1d', subreddit='bitcoin')\n",
    "popular_subreddits = query_data(URL_COM, q='bitcoin', size=0, aggs='subreddit', after='30d')\n",
    "\n",
    "#print(response['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subreddit': 'Bitcoin', 'size': 500, 'before': '0h', 'after': '6h'}\n",
      "https://api.pushshift.io/reddit/search/submission/\n",
      "129\n",
      "{'subreddit': 'Bitcoin', 'size': 500, 'before': '6h', 'after': '12h'}\n",
      "https://api.pushshift.io/reddit/search/submission/\n",
      "116\n",
      "{'subreddit': 'Bitcoin', 'size': 500, 'before': '12h', 'after': '18h'}\n",
      "https://api.pushshift.io/reddit/search/submission/\n",
      "96\n",
      "{'subreddit': 'Bitcoin', 'size': 500, 'before': '18h', 'after': '24h'}\n",
      "https://api.pushshift.io/reddit/search/submission/\n",
      "113\n",
      "{'subreddit': 'Bitcoin', 'size': 500, 'before': '24h', 'after': '30h'}\n",
      "https://api.pushshift.io/reddit/search/submission/\n",
      "171\n",
      "{'subreddit': 'Bitcoin', 'size': 500, 'before': '30h', 'after': '36h'}\n",
      "https://api.pushshift.io/reddit/search/submission/\n",
      "285\n",
      "{'subreddit': 'Bitcoin', 'size': 500, 'before': '36h', 'after': '42h'}\n",
      "https://api.pushshift.io/reddit/search/submission/\n",
      "288\n",
      "{'subreddit': 'Bitcoin', 'size': 500, 'before': '42h', 'after': '48h'}\n",
      "https://api.pushshift.io/reddit/search/submission/\n",
      "313\n",
      "{'subreddit': 'Bitcoin', 'size': 500, 'before': '48h', 'after': '54h'}\n",
      "https://api.pushshift.io/reddit/search/submission/\n",
      "444\n",
      "{'subreddit': 'Bitcoin', 'size': 500, 'before': '54h', 'after': '60h'}\n",
      "https://api.pushshift.io/reddit/search/submission/\n",
      "312\n",
      "{'subreddit': 'Bitcoin', 'size': 500, 'before': '60h', 'after': '66h'}\n",
      "https://api.pushshift.io/reddit/search/submission/\n",
      "132\n",
      "{'subreddit': 'Bitcoin', 'size': 500, 'before': '66h', 'after': '72h'}\n",
      "https://api.pushshift.io/reddit/search/submission/\n",
      "163\n",
      "idx \t author\tsubreddit\tparent_id\tscore\tlink_id\n"
     ]
    }
   ],
   "source": [
    "subreddit_list = []\n",
    "idx = 0\n",
    "for item in popular_subreddits['aggs']['subreddit']:\n",
    "    subreddit_list.append(item)\n",
    "    if idx > 20:\n",
    "        break\n",
    "    idx = idx + 1\n",
    "\n",
    "TIME_STEP = 6\n",
    "DAYS = 3\n",
    "\n",
    "data_temp = []\n",
    "for idx, sub in enumerate(subreddit_list): \n",
    "    data_temp = []\n",
    "    for idx in range(int(24/TIME_STEP * DAYS)):\n",
    "        _before = str(TIME_STEP*idx) + 'h'\n",
    "        _after = str(TIME_STEP*(idx+1)) + 'h'\n",
    "        r = query_data(URL_SUB, subreddit=sub['key'], size=500, before=_before, after=_after)['data']\n",
    "        data_temp.append(pd.DataFrame(r))\n",
    "        print(len(r))\n",
    "    break\n",
    "    \n",
    "    \n",
    "fields = ['author', 'subreddit', 'parent_id', 'score', 'link_id']\n",
    "\n",
    "idx = 0\n",
    "print('idx', '\\t', '\\t'.join(fields))\n",
    "for item in response['data']:\n",
    "    row = []\n",
    "    for field in fields:\n",
    "        row.append(str(item[field]))\n",
    "    #print(idx, '\\t', '\\t'.join(row))\n",
    "    idx = idx + 1\n",
    "    #print(item['author'], item['subreddit'], item)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7uzye6\n",
      "7uzz9o\n",
      "7v0057\n",
      "7v02kl\n",
      "7v05o9\n",
      "7v06jt\n",
      "7v07n7\n",
      "7v07vc\n",
      "7v090i\n",
      "7v09p1\n",
      "7v0ahv\n",
      "7v0aoj\n",
      "['dtoesxs', 'dtofzr1', 'dtoiozn', 'dtoj2mr', 'dtogmo2', 'dtogqkj', 'dtogt06', 'dtogwts', 'dtohhlc', 'dtohnv4', 'dtojiu0', 'dtondef', 'dtorha7', 'dtoi855', 'dtoivru', 'dtojvoi', 'dtonpfv', 'dtoo9p6', 'dtop9z4', 'dtor6q2', 'dtos01q', 'dtos4an', 'dtohvze', 'dtoio2n', 'dtoizko', 'dtoj8ya', 'dtojc0p', 'dtojqj3', 'dtojsjx', 'dtojuoy', 'dtorlrj', 'dtougmk']\n"
     ]
    }
   ],
   "source": [
    "#sequential calls\n",
    "print_fields = ['id', 'subreddit','author','score', 'num_comments']\n",
    "bitcoin_submissions = pd.concat(data_temp, ignore_index=True)\n",
    "#print(bitcoin_submissions.sort_values(by=['num_comments'], ascending=False)[print_fields])\n",
    "\n",
    "comment_ids = []\n",
    "\n",
    "for i, sub in bitcoin_submissions.iterrows():\n",
    "    print(sub.loc['id'])\n",
    "    comment_ids.extend(query_data('https://api.pushshift.io/reddit/submission/comment_ids/' + sub.loc['id'])['data'])\n",
    "    if i > 10:\n",
    "        break\n",
    "\n",
    "print(comment_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fut: 0\n",
      "fut: 1\n",
      "fut: 2\n",
      "fut: 3\n",
      "fut: 4\n",
      "fut: 5\n",
      "fut: 6\n",
      "fut: 7\n",
      "fut: 8\n",
      "fut: 9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "9355\n"
     ]
    }
   ],
   "source": [
    "#get comment ids for every submission obtained above\n",
    "#concurrent calls\n",
    "print_fields = ['id', 'subreddit','author','score', 'num_comments']\n",
    "bitcoin_submissions = pd.concat(data_temp, ignore_index=True)\n",
    "bitcoin_submissions = bitcoin_submissions.sort_values(by=['num_comments'], ascending=False).reset_index(drop=True)\n",
    "#print(bitcoin_submissions[print_fields])\n",
    "\n",
    "fut = []\n",
    "comment_ids = []\n",
    "num_calls = 10\n",
    "with FuturesSession(max_workers=10) as session:\n",
    "    for i, sub in bitcoin_submissions.iterrows():\n",
    "        fut.append(session.get('https://api.pushshift.io/reddit/submission/comment_ids/' + sub.loc['id']))\n",
    "        print('fut:', i)\n",
    "        if i >= num_calls - 1:\n",
    "            break\n",
    "        \n",
    "    for i in range(len(fut)):\n",
    "        print(i)\n",
    "        tmp = fut[i].result()\n",
    "        tmp = tmp.json()['data']\n",
    "        comment_ids.extend(tmp)\n",
    "\n",
    "print(len(comment_ids))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtkd1na\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "working\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "9354\n"
     ]
    }
   ],
   "source": [
    "#get data for every comment\n",
    "#print(comment_ids[-1])\n",
    "\n",
    "print(','.join(comment_ids[0:1]))\n",
    "#r = query_data(URL_COM, ids=','.join(comment_ids[0:2]))\n",
    "\n",
    "NUM_CONCAT = 500\n",
    "fut = []\n",
    "comment_data = []\n",
    "with FuturesSession(max_workers=5) as session:\n",
    "    _done = 0\n",
    "    idx = 0\n",
    "    while _done != -1:\n",
    "        print('working')\n",
    "        _end = _done + NUM_CONCAT\n",
    "        if _end >= len(comment_ids) + 1:\n",
    "            _end = -1\n",
    "        fut.append(session.get('https://api.pushshift.io/reddit/search/comment/?ids=' + ','.join(comment_ids[_done:_end])))\n",
    "        _done = _end\n",
    "    \n",
    "    for i in range(len(fut)):\n",
    "        print(i)\n",
    "        tmp = fut[i].result()\n",
    "        tmp = tmp.json()['data']\n",
    "        comment_data.extend(tmp)\n",
    "        \n",
    "    #print(r)\n",
    "print(len(comment_data))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type prefixes\n",
    "t1_\tComment\n",
    "t2_\tAccount\n",
    "t3_\tLink\n",
    "t4_\tMessage\n",
    "t5_\tSubreddit\n",
    "t6_\tAward"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "author_1 -> comment(score, ups) -> author_2\n",
    "\n",
    "simplified\n",
    "\n",
    "author_1 -> comment_on_sub -> author_2\n",
    "author_1 -> reply_on_comment -> author_2\n",
    "\n",
    "author_1 -> submission -> subreddit\n",
    "author_1 -> comment_on_sub -> subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'approved_at_utc': None, 'author': 'Asdn1220', 'author_flair_background_color': '', 'author_flair_css_class': None, 'author_flair_richtext': [], 'author_flair_text': None, 'author_flair_text_color': 'dark', 'author_flair_type': 'text', 'banned_at_utc': None, 'body': 'I am panicking', 'can_mod_post': False, 'collapsed': False, 'collapsed_reason': None, 'created_utc': 1517479281, 'distinguished': None, 'edited': False, 'id': 'dtkd1na', 'is_submitter': False, 'link_id': 't3_7uhqjf', 'mod_note': None, 'mod_reason_by': None, 'mod_reason_title': None, 'parent_id': 't3_7uhqjf', 'permalink': '/r/Bitcoin/comments/7uhqjf/daily_discussion_february_01_2018/dtkd1na/', 'retrieved_on': 1517479283, 'rte_mode': 'markdown', 'score': 1, 'stickied': False, 'subreddit': 'Bitcoin', 'subreddit_id': 't5_2s3qj'}\n"
     ]
    }
   ],
   "source": [
    "comments_df = pd.DataFrame(comment_data)\n",
    "print(comment_data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
